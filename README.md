# ğŸ§  Recomendador de Tenis Jordan con CLIP

## DescripciÃ³n del Proyecto
Este proyecto utiliza el modelo CLIP (Contrastive Language-Image Pretraining) de OpenAI para crear un sistema de recomendaciÃ³n de tenis Jordan. El sistema puede:

- ğŸ” **Clasificar** una imagen de tenis en 31 modelos diferentes de Jordan
- ğŸ›ï¸ **Recomendar** los tenis mÃ¡s parecidos visualmente del catÃ¡logo
- ğŸ“ **Describir** las caracterÃ­sticas visuales detectadas en la imagen

## CaracterÃ­sticas Principales

### âœ¨ Data Augmentation
- Utiliza flip horizontal para mayor robustez
- Combina embeddings de imagen original y volteada
- Mejora la invarianza a orientaciÃ³n

### ğŸ¯ ClasificaciÃ³n Multimodal
- Compara embeddings de imagen vs texto
- 31 clases de modelos Jordan predefinidas
- Sistema de confianza basado en similitud coseno

### ğŸ–¼ï¸ AnÃ¡lisis Visual Detallado
- DescripciÃ³n automÃ¡tica de caracterÃ­sticas
- DetecciÃ³n de colores, materiales y estilos
- Top 3 caracterÃ­sticas con porcentajes de confianza

## Estructura del Proyecto

```
tarea1/
â”œâ”€â”€ clasificacion_v2.py    # CÃ³digo principal
â”œâ”€â”€ requirements.txt       # Dependencias
â”œâ”€â”€ dataset/              # Carpeta con imÃ¡genes organizadas por clase
â”‚   â”œâ”€â”€ Air_Jordan_1/
â”‚   â”œâ”€â”€ Air_Jordan_3/
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md            # Este archivo
```

## InstalaciÃ³n

1. Clona el repositorio:
```bash
git clone https://github.com/pepemt/tarea_clasificacion.git
cd tarea_clasificacion
```

2. Instala las dependencias:
```bash
pip install -r requirements.txt
```

3. Ejecuta el cÃ³digo:
```bash
python clasificacion_v2.py
```

## Uso

```python
# Recomendar tenis similares
recomendar("mi_imagen.jpg", top_k=5)

# Clasificar sin data augmentation
recomendar("mi_imagen.jpg", use_augmentation=False)
```

## TecnologÃ­as Utilizadas

- **PyTorch**: Framework de deep learning
- **CLIP**: Modelo multimodal de OpenAI
- **PIL/Pillow**: Procesamiento de imÃ¡genes
- **Matplotlib**: VisualizaciÃ³n de resultados
- **NumPy**: Operaciones numÃ©ricas

## Autor
JosÃ© Tahuilan

## Conclusiones

El modelo CLIP permite representar imÃ¡genes y texto en un mismo espacio semÃ¡ntico, facilitando la clasificaciÃ³n y recomendaciÃ³n basada en similitud visual. El uso de Data Augmentation mejora significativamente la robustez del sistema ante variaciones de orientaciÃ³n.